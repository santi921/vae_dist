{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import plot, init_notebook_mode, iplot\n",
    "import plotly.express as px\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "from vae_dist.dataset.fields import mat_pull, split_and_filter\n",
    "\n",
    "import numpy as np \n",
    "from vae_dist.dataset.fields import mat_pull\n",
    "from vae_dist.data.augmentation import Augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vfield(mat, cutoff = 95, min_max = True, scale = 10):\n",
    "        x = mat #dataset_test.data[0] \n",
    "        x = x.reshape(50, 50, 50, 3)\n",
    "        \n",
    "        u_1, v_1, w_1 = split_and_filter(\n",
    "            x, cutoff=cutoff, std_mean=False, min_max=False\n",
    "        )\n",
    "        a, b, c = np.meshgrid(\n",
    "                np.arange(-5.0, 5.0, 0.2),\n",
    "                np.arange(-5.0, 5.0, 0.2),\n",
    "                np.arange(-5.0, 5.0, 0.2)\n",
    "                )\n",
    "\n",
    "        #max value of each dimension\n",
    "        max_u = np.max(u_1)\n",
    "        max_v = np.max(v_1)\n",
    "        max_w = np.max(w_1)\n",
    "        print(max_u, max_v, max_w)\n",
    "        \n",
    "        cones = go.Cone(\n",
    "                x=a.flatten(), \n",
    "                y=b.flatten(), \n",
    "                z=c.flatten(), \n",
    "                u=u_1 ,\n",
    "                v=v_1 , \n",
    "                w=w_1 ,\n",
    "                sizeref=scale,)\n",
    "                #opacity=0.0) \n",
    "                \n",
    "        layout = go.Layout(\n",
    "                title='Cones',\n",
    "                width=700,\n",
    "                height=700,\n",
    "                        #sizeref=0.5,\n",
    "                        #anchor='tail'\n",
    "                )\n",
    "\n",
    "        fig = go.Figure(data=cones,layout=layout)\n",
    "        iplot(fig)\n",
    "\n",
    "\n",
    "def write_mat(mat, filename, start_line='', spacing = 0.3):\n",
    "    # write seven empty lines \n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        for i in range(6):\n",
    "            if (start_line != '' and i == 0):\n",
    "                f.write(start_line)\n",
    "            f.write(\"\\n\")\n",
    "        \n",
    "        for i in range(mat.shape[0]):\n",
    "            for j in range(mat.shape[1]):\n",
    "                for k in range(mat.shape[2]):\n",
    "                    # round to 2 decimal places\n",
    "                    i_ = np.around(i - np.floor(mat.shape[0]/2), decimals=4)\n",
    "                    j_ = np.around(j - np.floor(mat.shape[1]/2), decimals=4)\n",
    "                    k_ = np.around(k - np.floor(mat.shape[2]/2), decimals=4)\n",
    "                    #print(mat[i][j][k])\n",
    "                    f.write(\"{:.3f} {:.3f} {:.3f} {:.6f} {:.6f} {:.6f}\\n\".format(\n",
    "                        i_*spacing, j_*spacing, k_*spacing, \n",
    "                        mat[i][j][k][0], mat[i][j][k][1], mat[i][j][k][2])\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta= {'steps_x': 50, 'steps_y': 50, 'steps_z': 50, 'step_size_x': 0.2, 'step_size_y': 0.2, 'step_size_z': 0.2, 'first_line': '#Sample Density: 25 25 25; Volume: Box: 5.000000 5.000000 5.000000\\n'}\n",
    "mat_aug_reshape = np.zeros((meta[\"steps_x\"], meta['steps_y'], meta['steps_z'], 3))\n",
    "\n",
    "up = np.array([0, 0, 1.0])\n",
    "down = np.array([0, 0, -1.0])\n",
    "left = np.array([0, -1.0, 0])\n",
    "right = np.array([0, 1.0, 0])\n",
    "front = np.array([-1.0, 0, 0])\n",
    "back = np.array([1.0, 0, 0])\n",
    "\n",
    "mat_up = np.zeros((meta[\"steps_x\"], meta['steps_y'], meta['steps_z'], 3))\n",
    "mat_down = np.zeros((meta[\"steps_x\"], meta['steps_y'], meta['steps_z'], 3))\n",
    "mat_left = np.zeros((meta[\"steps_x\"], meta['steps_y'], meta['steps_z'], 3))\n",
    "mat_right = np.zeros((meta[\"steps_x\"], meta['steps_y'], meta['steps_z'], 3))\n",
    "mat_front = np.zeros((meta[\"steps_x\"], meta['steps_y'], meta['steps_z'], 3))\n",
    "mat_back = np.zeros((meta[\"steps_x\"], meta['steps_y'], meta['steps_z'], 3))\n",
    "mat_sink = np.zeros((meta[\"steps_x\"], meta['steps_y'], meta['steps_z'], 3))\n",
    "mat_source = np.zeros((meta[\"steps_x\"], meta['steps_y'], meta['steps_z'], 3))\n",
    "\n",
    "mat_up[:, :, :, :] = up\n",
    "mat_down[:, :, :, :] = down\n",
    "mat_left[:, :, :, :] = left\n",
    "mat_right[:, :, :, :] = right\n",
    "mat_front[:, :, :, :] = front\n",
    "mat_back[:, :, :, :] = back\n",
    "\n",
    "# get center index of the matrix\n",
    "center = np.array([meta[\"steps_x\"], meta['steps_y'], meta['steps_z']]) / 2\n",
    "print(center)\n",
    "# get direction to origin at each point\n",
    "\n",
    "\n",
    "benchmarks = [mat_up, mat_down, mat_left, mat_right, mat_front, mat_back]\n",
    "file_list = ['up', 'down', 'left', 'right', 'front', 'back']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./baseline_fields/\"\n",
    "\n",
    "for i, mat in enumerate(benchmarks):\n",
    "    file = file_list[i]\n",
    "    write_mat(\n",
    "        mat,\n",
    "        output_dir + file.split(\".\")[0] + \".dat\",\n",
    "        start_line = meta['first_line'],\n",
    "        spacing = meta['step_size_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_field = mat_pull(\"./baseline_fields/left.dat\")\n",
    "original_field = original_field.reshape(1, 3, 50, 50, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_vfield(\n",
    "        original_field,  \n",
    "        cutoff = 0,\n",
    "        scale = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_0 = mat_pull(\"./augmented_baselines/left_0.dat\")\n",
    "field_1 = mat_pull(\"./augmented_baselines/left_1.dat\")\n",
    "field_2 = mat_pull(\"./augmented_baselines/left_2.dat\")\n",
    "field_3 = mat_pull(\"./augmented_baselines/left_3.dat\")\n",
    "field_4 = mat_pull(\"./augmented_baselines/left_4.dat\")\n",
    "field_5 = mat_pull(\"./augmented_baselines/left_5.dat\")\n",
    "field_6 = mat_pull(\"./augmented_baselines/left_6.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_vfield(\n",
    "        field_0,  \n",
    "        cutoff = 0,\n",
    "        scale = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_vfield(\n",
    "        field_1,  \n",
    "        cutoff = 0,\n",
    "        scale = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_vfield(\n",
    "        field_3,  \n",
    "        cutoff = 0,\n",
    "        scale = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrangle data mean 1.1772095293703486, std 6.992790413113798\n",
      "wrangle min 0.0008873698092109061, max 4370.6400039582795\n",
      "22.15558076871174\n",
      "Data shape:  (186, 3, 21, 21, 21)\n",
      "Data type:  float64\n",
      "------------------------- Preprocessing Info -------------------------\n",
      "Helmholtz-Hodge decomposition applied:  False\n",
      "Lower filter applied:  True\n",
      "Log scale applied:  False\n",
      "Standardization applied:  True\n",
      "Min max scaling applied:  True\n",
      "Wrangling outliers applied:  True\n",
      "------------------------- Data Info -------------------------\n",
      "Mean value in dataset:  -0.008502826629883897\n",
      "Standard deviation in dataset:  0.05034438558765044\n",
      "Largest value in dataset:  0.88\n",
      "Smallest value in dataset:  -0.97\n",
      "Nan values in dataset:  False\n",
      "Inf values in dataset:  False\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from vae_dist.dataset.dataset import FieldDatasetSupervised\n",
    "root = \"../data/cpet/\"\n",
    "supervised_file = \"../data/protein_data.csv\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "dataset_vanilla = FieldDatasetSupervised(\n",
    "    root, \n",
    "    supervised_file,\n",
    "    transform=False, \n",
    "    augmentation=False,\n",
    "    standardize=True,\n",
    "    lower_filter=True,\n",
    "    log_scale=False, \n",
    "    min_max_scale=True,\n",
    "    wrangle_outliers=True,\n",
    "    scalar=False,\n",
    "    device=device, \n",
    "    offset=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_vanilla[[0,2,3]][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5])\n",
      "torch.float32\n",
      "torch.Size([3])\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "import torch\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "print(input.shape)\n",
    "print(input.dtype)\n",
    "target = torch.randint(5, (3,), dtype=torch.int64)\n",
    "print(target.shape)\n",
    "print(target.dtype)\n",
    "loss = F.cross_entropy(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bondnet_e3nn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
