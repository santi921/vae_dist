{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytorch_lightning'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_34889/3271926980.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'autoreload'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvae_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVAE\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbaselineVAEAutoencoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvae_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvae_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFieldDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/vae_dist/vae_dist/core/VAE.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpytorch_lightning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytorch_lightning'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "from vae_dist.core.VAE import baselineVAEAutoencoder\n",
    "from vae_dist.core.training import train\n",
    "from vae_dist.dataset.dataset import FieldDataset\n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "root = \"../../data/cpet/\"\n",
    "# load model to gpu\n",
    "dataset_vanilla = FieldDataset(\n",
    "    root, \n",
    "    transform=None, \n",
    "    augmentation=None, \n",
    "    device=device\n",
    "    )\n",
    "\n",
    "\n",
    "dataset_loader_full = torch.utils.data.DataLoader(dataset_vanilla, batch_size=40, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = baselineVAEAutoencoder(\n",
    "    irreps = None, # not used rn \n",
    "    in_channels = 3,\n",
    "    out_channels = 16,\n",
    "    kernel_size = 5,\n",
    "    stride = 1,\n",
    "    padding = 0,\n",
    "    dilation = 1,\n",
    "    groups = 1,\n",
    "    bias = True,\n",
    "    padding_mode = 'zeros',\n",
    "    #padding_mode = 'constant',\n",
    "    latent_dim = 4, # final vae hidden layer \n",
    "    num_layers = 2, # not used rn \n",
    "    hidden_dim = 32,\n",
    "    activation = 'relu', # not used rn \n",
    "    dropout = 0.1, # not used rn \n",
    "    batch_norm = False, # not used rn \n",
    "    beta = 1.0,\n",
    "    device = device, \n",
    "    loss = 'elbo'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, dataset_loader_full, device = device, epochs = 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightning Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santiagovargas/anaconda3/envs/bondnet/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from vae_dist.core.CNN import CNNAutoencoderLightning\n",
    "from vae_dist.dataset.dataset import FieldDataset\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "root = \"../../data/cpet/\"\n",
    "# load model to gpu\n",
    "dataset_vanilla = FieldDataset(\n",
    "    root, \n",
    "    transform=None, \n",
    "    augmentation=None, \n",
    "    device=device\n",
    "    )\n",
    "\n",
    "#torch.multiprocessing.set_start_method('spawn')# good solution !!!!\n",
    "\n",
    "# train test split - randomly split dataset into train and test\n",
    "train_size = int(0.8 * len(dataset_vanilla))\n",
    "test_size = len(dataset_vanilla) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset_vanilla, [train_size, test_size])\n",
    "\n",
    "\n",
    "dataset_loader_full = torch.utils.data.DataLoader(\n",
    "    dataset_vanilla, \n",
    "    batch_size=40,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "dataset_loader_train= torch.utils.data.DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=10,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "dataset_loader_test= torch.utils.data.DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=10,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNAutoencoderLightning(\n",
    "    irreps = None, # not used rn \n",
    "    in_channels = 3,\n",
    "    out_channels = 16,\n",
    "    kernel_size = 5,\n",
    "    stride = 1,\n",
    "    padding = 0,\n",
    "    dilation = 1,\n",
    "    groups = 1,\n",
    "    bias = True,\n",
    "    padding_mode = 'zeros',\n",
    "    latent_dim = 4, # final vae hidden layer \n",
    "    num_layers = 2, # not used rn \n",
    "    hidden_dim = 32,\n",
    "    activation = 'relu', # not used rn \n",
    "    dropout = 0.1, # not used rn \n",
    "    batch_norm = False, # not used rn \n",
    "    beta = 1.0,\n",
    "    device = device,\n",
    "    learning_rate = 0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 2.5 M \n",
      "1 | decoder | Sequential | 2.6 M \n",
      "---------------------------------------\n",
      "5.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.1 M     Total params\n",
      "20.486    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santiagovargas/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:491: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
      "  category=PossibleUserWarning,\n",
      "/home/santiagovargas/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:229: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santiagovargas/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n",
      "/home/santiagovargas/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1599: PossibleUserWarning: The number of training batches (29) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 37/37 [00:00<00:00, 324.72it/s, loss=7.33e+03, v_num=18]Epoch 00026: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch 36: 100%|██████████| 37/37 [00:00<00:00, 321.59it/s, loss=212, v_num=18]     Epoch 00037: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 47: 100%|██████████| 37/37 [00:00<00:00, 363.46it/s, loss=249, v_num=18]     Epoch 00048: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 58: 100%|██████████| 37/37 [00:00<00:00, 336.41it/s, loss=7.36e+03, v_num=18]Epoch 00059: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch 69: 100%|██████████| 37/37 [00:00<00:00, 319.19it/s, loss=7.34e+03, v_num=18]Epoch 00070: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch 80: 100%|██████████| 37/37 [00:00<00:00, 332.14it/s, loss=275, v_num=18]     Epoch 00081: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch 88: 100%|██████████| 37/37 [00:00<00:00, 210.83it/s, loss=185, v_num=18]     \n"
     ]
    }
   ],
   "source": [
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "trainer = pl.Trainer(\n",
    "    limit_train_batches=100, \n",
    "    max_epochs=100, \n",
    "    accelerator='gpu', \n",
    "    devices = [0],\n",
    "    accumulate_grad_batches=5, \n",
    "    callbacks=[\n",
    "        pl.callbacks.EarlyStopping(monitor='val_loss', patience=50, verbose = False),\n",
    "        lr_monitor]\n",
    "    )\n",
    "\n",
    "trainer.fit(model, dataset_loader_train, dataset_loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santiagovargas/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:442: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  f\"Setting `Trainer(gpus={gpus!r})` is deprecated in v1.7 and will be removed\"\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/santiagovargas/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n",
      "/home/santiagovargas/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1599: PossibleUserWarning: The number of training batches (29) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  category=PossibleUserWarning,\n",
      "/home/santiagovargas/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:491: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
      "  category=PossibleUserWarning,\n",
      "/home/santiagovargas/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:229: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n",
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Finding best initial lr: 100%|██████████| 100/100 [00:00<00:00, 259.80it/s]\n",
      "Restoring states from the checkpoint path at /home/santiagovargas/dev/vae_dist/vae_dist/scripts/.lr_find_c65f8731-106e-4b10-9c5a-7130e0a543ea.ckpt\n",
      "Restored all states from the checkpoint file at /home/santiagovargas/dev/vae_dist/vae_dist/scripts/.lr_find_c65f8731-106e-4b10-9c5a-7130e0a543ea.ckpt\n",
      "/home/santiagovargas/anaconda3/envs/bondnet/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.585775750291837e-08"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "trainer_lr = pl.Trainer(auto_lr_find=True, max_epochs=100, gpus=1)\n",
    "lr_finder = trainer_lr.tuner.lr_find(model, dataset_loader_train, dataset_loader_test)\n",
    "fig = lr_finder.plot(suggest=True)\n",
    "fig.show()\n",
    "lr_finder.suggestion()\n",
    "#trainer.tune(model)\n",
    "#model.learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/santiagovargas/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/loops/utilities.py:97: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  category=PossibleUserWarning,\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 2.5 M \n",
      "1 | decoder | Sequential | 2.6 M \n",
      "---------------------------------------\n",
      "5.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.1 M     Total params\n",
      "20.486    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santiagovargas/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:491: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
      "  category=PossibleUserWarning,\n",
      "/home/santiagovargas/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:229: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n",
      "/home/santiagovargas/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n",
      "/home/santiagovargas/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1599: PossibleUserWarning: The number of training batches (29) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 37/37 [00:00<00:00, 335.19it/s, loss=176, v_num=21]     Epoch 00012: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch 22: 100%|██████████| 37/37 [00:00<00:00, 354.09it/s, loss=7.38e+03, v_num=21]Epoch 00023: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 33: 100%|██████████| 37/37 [00:00<00:00, 324.97it/s, loss=157, v_num=21]     Epoch 00034: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 44: 100%|██████████| 37/37 [00:00<00:00, 350.15it/s, loss=7.28e+03, v_num=21]Epoch 00045: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch 55: 100%|██████████| 37/37 [00:00<00:00, 342.80it/s, loss=210, v_num=21]     Epoch 00056: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch 66: 100%|██████████| 37/37 [00:00<00:00, 350.53it/s, loss=7.39e+03, v_num=21]Epoch 00067: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch 999: 100%|██████████| 37/37 [00:00<00:00, 333.57it/s, loss=292, v_num=21]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999: 100%|██████████| 37/37 [00:00<00:00, 201.26it/s, loss=292, v_num=21]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainer_lr = pl.Trainer(accelerator='gpu', devices = [0], accumulate_grad_batches=5, auto_lr_find=True)\n",
    "trainer_lr.fit(model, dataset_loader_train, dataset_loader_test)\n",
    "#lr_finder = trainer_lr.tuner.lr_find(model)\n",
    "#fig = lr_finder.plot(suggest=True)\n",
    "#fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santiagovargas/anaconda3/envs/bondnet/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from vae_dist.core.VAE import baselineVAEAutoencoder\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from vae_dist.dataset.dataset import FieldDataset\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "root = \"../../data/cpet/\"\n",
    "# load model to gpu\n",
    "dataset_vanilla = FieldDataset(\n",
    "    root, \n",
    "    transform=None, \n",
    "    augmentation=None, \n",
    "    device=device\n",
    "    )\n",
    "\n",
    "#torch.multiprocessing.set_start_method('spawn')# good solution !!!!\n",
    "\n",
    "# train test split - randomly split dataset into train and test\n",
    "train_size = int(0.8 * len(dataset_vanilla))\n",
    "test_size = len(dataset_vanilla) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset_vanilla, [train_size, test_size])\n",
    "\n",
    "\n",
    "dataset_loader_full = torch.utils.data.DataLoader(\n",
    "    dataset_vanilla, \n",
    "    batch_size=40,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "dataset_loader_train= torch.utils.data.DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=10,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "dataset_loader_test= torch.utils.data.DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=10,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | fc_mu   | Linear     | 2.5 M \n",
      "1 | fc_var  | Linear     | 2.5 M \n",
      "2 | encoder | Sequential | 6.0 K \n",
      "3 | decoder | Sequential | 2.6 M \n",
      "---------------------------------------\n",
      "7.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.6 M     Total params\n",
      "30.548    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/29 [00:00<?, ?it/s] tensor(1.1889, device='cuda:0', grad_fn=<MeanBackward0>) tensor(659.1617, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch 0:   3%|▎         | 1/29 [00:00<00:00, 111.09it/s, loss=660, v_num=41]tensor(16.2656, device='cuda:0', grad_fn=<MeanBackward0>) tensor(26.1597, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch 0:   7%|▋         | 2/29 [00:00<00:00, 131.85it/s, loss=351, v_num=41]tensor(150.1526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(3.3384, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch 0:  10%|█         | 3/29 [00:00<00:00, 145.00it/s, loss=285, v_num=41]tensor(2678.7273, device='cuda:0', grad_fn=<MeanBackward0>) tensor(12734.5752, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch 0:  14%|█▍        | 4/29 [00:00<00:00, 148.01it/s, loss=4.07e+03, v_num=41]tensor(90.4650, device='cuda:0', grad_fn=<MeanBackward0>) tensor(469.7871, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch 0:  17%|█▋        | 5/29 [00:00<00:00, 151.45it/s, loss=3.37e+03, v_num=41]tensor(221833.8750, device='cuda:0', grad_fn=<MeanBackward0>) tensor(117.0944, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch 0:  21%|██        | 6/29 [00:00<00:00, 155.35it/s, loss=3.98e+04, v_num=41]tensor(13.1986, device='cuda:0', grad_fn=<MeanBackward0>) tensor(391.5279, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch 0:  24%|██▍       | 7/29 [00:00<00:00, 156.92it/s, loss=3.42e+04, v_num=41]tensor(6332712., device='cuda:0', grad_fn=<MeanBackward0>) tensor(7.5762, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch 0:  28%|██▊       | 8/29 [00:00<00:00, 158.11it/s, loss=8.21e+05, v_num=41]tensor(15.3585, device='cuda:0', grad_fn=<MeanBackward0>) tensor(819.5451, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch 0:  31%|███       | 9/29 [00:00<00:00, 159.05it/s, loss=7.3e+05, v_num=41] tensor(5.7720, device='cuda:0', grad_fn=<MeanBackward0>) tensor(156.4275, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Epoch 0:  10%|█         | 3/29 [04:40<40:27, 93.38s/it, loss=nan, v_num=39] um=41]\n",
      "Epoch 0:  28%|██▊       | 8/29 [04:24<11:33, 33.05s/it, loss=1.99e+11, v_num=40] \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected parameter scale (Tensor of shape (10, 32)) of distribution Normal(loc: torch.Size([10, 32]), scale: torch.Size([10, 32])) to satisfy the constraint GreaterThan(lower_bound=0.0), but found invalid values:\ntensor([[5.6074e-01, 2.8725e-01, 3.4778e-01, 3.7265e-01, 2.7217e-01, 8.6194e-01,\n         4.2021e-01, 6.1540e-01, 5.0851e-01, 3.1090e-01, 2.5962e-01, 2.7295e-01,\n         2.5502e-01, 3.6191e-01, 4.5074e-01, 4.0503e-01, 3.7563e-01, 3.6719e-01,\n         3.7209e-01, 2.6678e-01, 5.9318e-01, 5.3631e-01, 3.2544e-01, 2.2601e-01,\n         4.4353e-01, 2.5320e-01, 4.5085e-01, 3.6082e-01, 3.0879e-01, 5.5971e-01,\n         4.9405e-01, 3.4750e-01],\n        [7.6514e-01, 7.6289e-01, 7.3498e-01, 7.6757e-01, 5.4888e-01, 1.0780e+00,\n         6.3804e-01, 8.1713e-01, 1.2171e+00, 6.7644e-01, 6.7080e-01, 5.9911e-01,\n         6.6003e-01, 6.2329e-01, 1.0461e+00, 6.1720e-01, 7.6741e-01, 7.6627e-01,\n         6.6525e-01, 6.9646e-01, 8.0343e-01, 7.4814e-01, 6.2838e-01, 5.8326e-01,\n         6.9730e-01, 6.2501e-01, 6.9498e-01, 6.5162e-01, 6.0239e-01, 7.7598e-01,\n         7.3291e-01, 6.1232e-01],\n        [3.2665e-02, 4.3015e-02, 4.4195e-02, 6.1899e-02, 5.5789e-03, 1.5414e-01,\n         9.6356e-03, 3.6877e-02, 2.7483e-01, 2.8343e-02, 3.4827e-02, 1.5150e-02,\n         3.3985e-02, 1.6897e-02, 1.5092e-01, 9.2074e-03, 6.2242e-02, 6.1188e-02,\n         1.0748e-02, 3.6200e-02, 4.1396e-02, 3.1716e-02, 8.8537e-03, 1.4071e-02,\n         2.6375e-02, 2.6747e-02, 1.2783e-02, 2.5835e-02, 6.6343e-03, 3.3068e-02,\n         3.0170e-02, 1.3684e-02],\n        [8.3379e-01, 7.6398e-01, 9.1090e-01, 9.6201e-01, 6.7338e-01, 1.1785e+00,\n         7.3362e-01, 8.8848e-01, 1.1357e+00, 8.2027e-01, 6.9933e-01, 7.0585e-01,\n         6.6902e-01, 8.1132e-01, 1.0093e+00, 7.1613e-01, 9.5998e-01, 9.9003e-01,\n         8.7033e-01, 7.0074e-01, 8.5759e-01, 9.2940e-01, 7.8037e-01, 6.3572e-01,\n         8.8843e-01, 6.4847e-01, 7.9280e-01, 7.9467e-01, 7.3082e-01, 8.4703e-01,\n         9.1469e-01, 7.8461e-01],\n        [3.6605e-04, 1.8229e-06, 2.0475e-03, 4.7173e-03, 4.4749e-05, 4.0856e-02,\n         3.4350e-04, 5.8419e-04, 3.5253e-05, 5.0179e-04, 1.9109e-06, 4.2930e-05,\n         2.3307e-06, 7.5691e-04, 2.6894e-05, 2.7842e-04, 8.5619e-03, 6.3946e-03,\n         1.0467e-03, 1.7476e-06, 4.0787e-04, 1.1375e-02, 1.5742e-04, 1.9764e-06,\n         4.3740e-03, 3.2210e-06, 2.6666e-04, 6.4308e-04, 8.7734e-05, 3.7433e-04,\n         9.3748e-03, 5.1889e-04],\n        [6.0411e-20, 0.0000e+00, 2.9393e-02, 3.4464e+03, 1.1648e-19, 1.9908e-03,\n         2.8654e-19, 1.6228e-22, 1.0734e-42, 3.2472e-13, 0.0000e+00, 1.0993e-25,\n         0.0000e+00, 7.9197e-16, 6.7683e-43, 1.5610e-18, 2.1801e+06, 5.3252e+05,\n         9.4358e-15, 0.0000e+00, 2.9404e-21, 1.9890e-10, 1.0555e-18, 0.0000e+00,\n         3.8014e-13, 0.0000e+00, 1.2837e-19, 1.4349e-15, 1.8493e-19, 4.7813e-20,\n         2.7426e-12, 7.8435e-19],\n        [2.6098e-01, 1.2368e-01, 4.9007e-01, 7.0046e-01, 1.4205e-01, 7.0817e-01,\n         2.4195e-01, 2.9552e-01, 2.7868e-01, 2.7703e-01, 1.0085e-01, 1.7409e-01,\n         9.0759e-02, 4.2809e-01, 2.5736e-01, 2.2880e-01, 7.1906e-01, 6.3564e-01,\n         4.9630e-01, 1.0225e-01, 2.4795e-01, 7.9825e-01, 2.2116e-01, 1.0193e-01,\n         5.3871e-01, 1.0867e-01, 2.5201e-01, 3.3489e-01, 1.8592e-01, 3.0929e-01,\n         6.7096e-01, 3.6450e-01],\n        [8.6777e-01, 8.0322e-01, 9.2022e-01, 9.6998e-01, 6.9284e-01, 1.2004e+00,\n         7.6920e-01, 9.1880e-01, 1.1682e+00, 8.3030e-01, 7.2498e-01, 7.2455e-01,\n         7.0668e-01, 7.9526e-01, 1.0470e+00, 7.4680e-01, 9.6388e-01, 9.8772e-01,\n         8.5914e-01, 7.3644e-01, 8.9028e-01, 9.1960e-01, 7.9143e-01, 6.6784e-01,\n         8.7327e-01, 6.8052e-01, 8.2445e-01, 8.0122e-01, 7.5363e-01, 8.7387e-01,\n         9.1059e-01, 7.7333e-01],\n        [5.7221e-05, 9.6137e-10, 3.4005e+00, 4.5710e+01, 9.7215e-05, 1.4940e-01,\n         8.2537e-05, 1.8138e-05, 5.8216e-08, 2.1767e-02, 6.4495e-10, 4.2185e-05,\n         8.2099e-10, 2.3474e-04, 3.6756e-08, 1.0737e-04, 1.2288e+02, 1.2146e+02,\n         2.8269e-04, 6.1196e-10, 2.6223e-05, 1.5377e-03, 1.7818e-04, 1.8856e-09,\n         6.2675e-04, 1.2442e-09, 8.0998e-05, 2.9331e-04, 1.2841e-04, 4.7653e-05,\n         9.5914e-04, 4.6535e-05],\n        [8.1250e-01, 7.8120e-01, 9.0188e-01, 9.7769e-01, 6.3905e-01, 1.1113e+00,\n         6.9280e-01, 8.5058e-01, 1.1329e+00, 8.3771e-01, 7.1455e-01, 7.0784e-01,\n         7.0050e-01, 7.1353e-01, 1.0250e+00, 6.8427e-01, 9.5482e-01, 9.9763e-01,\n         7.3535e-01, 7.2395e-01, 8.3399e-01, 8.1253e-01, 7.0790e-01, 6.5680e-01,\n         7.8060e-01, 6.7418e-01, 7.6160e-01, 7.3975e-01, 6.8889e-01, 8.2607e-01,\n         7.9312e-01, 6.8589e-01]], device='cuda:0', grad_fn=<ExpBackward0>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_371496/366286051.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_loader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_loader_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lightning_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m         call._call_and_handle_interrupt(\n\u001b[0;32m--> 604\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m         )\n\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_TunerExitException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0mmodel_connected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         )\n\u001b[0;32m--> 645\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.__class__.__name__}: trainer tearing down\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_training_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_EVALUATE_OUTPUT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/loops/loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/loops/fit_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_to_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_to_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/loops/loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_batch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                 \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_progress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincrement_processed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/loops/loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_frequencies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"batch_idx\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             )\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/loops/loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, optimizers, kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hiddens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_optimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim_progress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_position\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# automatic optimization assumes a loss needs to be returned for extras to be considered as the batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\u001b[0m in \u001b[0;36m_run_optimization\u001b[0;34m(self, kwargs, optimizer)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;31m# the `batch_idx` is optional with inter-batch parallelism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"batch_idx\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsume_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\u001b[0m in \u001b[0;36m_optimizer_step\u001b[0;34m(self, optimizer, opt_idx, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0mon_tpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTPUAccelerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m             \u001b[0musing_native_amp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp_backend\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mAMPType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNATIVE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m             \u001b[0musing_lbfgs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_lbfgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m         )\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(self, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1341\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[LightningModule]{pl_module.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1342\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m         \u001b[0;31m# restore current_fx when nested context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/core/module.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_idx, optimizer_closure, on_tpu, using_native_amp, using_lbfgs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m         \"\"\"\n\u001b[0;32m-> 1661\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimizer_zero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/core/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mstep_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_after_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/strategies/strategy.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, opt_idx, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLightningModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         return self.precision_plugin.optimizer_step(\n\u001b[0;32m--> 235\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         )\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, model, optimizer_idx, closure, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;34m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mclosure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_closure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_track_grad_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\u001b[0m in \u001b[0;36m_wrap_closure\u001b[0;34m(self, model, optimizer, optimizer_idx, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mconsistent\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mPrecisionPlugin\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0msubclasses\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0;32mpass\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mdirectly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mclosure_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_closure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mclosure_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\u001b[0m in \u001b[0;36mclosure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mClosureResult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mstep_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosure_loss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\u001b[0m in \u001b[0;36m_training_step\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \"\"\"\n\u001b[1;32m    405\u001b[0m         \u001b[0;31m# manually capture logged metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0mtraining_step_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_strategy_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training_step\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_call_strategy_hook\u001b[0;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[Strategy]{self.strategy.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;31m# restore current_fx when nested context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/pytorch_lightning/strategies/strategy.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingStep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpost_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/vae_dist/vae_dist/core/VAE.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;31m# sample z from q\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_var\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/torch/distributions/normal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNormal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet/lib/python3.7/site-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                     raise ValueError(\n\u001b[0;32m---> 56\u001b[0;31m                         \u001b[0;34mf\"Expected parameter {param} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m                         \u001b[0;34mf\"({type(value).__name__} of shape {tuple(value.shape)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                         \u001b[0;34mf\"of distribution {repr(self)} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected parameter scale (Tensor of shape (10, 32)) of distribution Normal(loc: torch.Size([10, 32]), scale: torch.Size([10, 32])) to satisfy the constraint GreaterThan(lower_bound=0.0), but found invalid values:\ntensor([[5.6074e-01, 2.8725e-01, 3.4778e-01, 3.7265e-01, 2.7217e-01, 8.6194e-01,\n         4.2021e-01, 6.1540e-01, 5.0851e-01, 3.1090e-01, 2.5962e-01, 2.7295e-01,\n         2.5502e-01, 3.6191e-01, 4.5074e-01, 4.0503e-01, 3.7563e-01, 3.6719e-01,\n         3.7209e-01, 2.6678e-01, 5.9318e-01, 5.3631e-01, 3.2544e-01, 2.2601e-01,\n         4.4353e-01, 2.5320e-01, 4.5085e-01, 3.6082e-01, 3.0879e-01, 5.5971e-01,\n         4.9405e-01, 3.4750e-01],\n        [7.6514e-01, 7.6289e-01, 7.3498e-01, 7.6757e-01, 5.4888e-01, 1.0780e+00,\n         6.3804e-01, 8.1713e-01, 1.2171e+00, 6.7644e-01, 6.7080e-01, 5.9911e-01,\n         6.6003e-01, 6.2329e-01, 1.0461e+00, 6.1720e-01, 7.6741e-01, 7.6627e-01,\n         6.6525e-01, 6.9646e-01, 8.0343e-01, 7.4814e-01, 6.2838e-01, 5.8326e-01,\n         6.9730e-01, 6.2501e-01, 6.9498e-01, 6.5162e-01, 6.0239e-01, 7.7598e-01,\n         7.3291e-01, 6.1232e-01],\n        [3.2665e-02, 4.3015e-02, 4.4195e-02, 6.1899e-02, 5.5789e-03, 1.5414e-01,\n         9.6356e-03, 3.6877e-02, 2.7483e-01, 2.8343e-02, 3.4827e-02, 1.5150e-02,\n         3.3985e-02, 1.6897e-02, 1.5092e-01, 9.2074e-03, 6.2242e-02, 6.1188e-02,\n         1.0748e-02, 3.6200e-02, 4.1396e-02, 3.1716e-02, 8.8537e-03, 1.4071e-02,\n         2.6375e-02, 2.6747e-02, 1.2783e-02, 2.5835e-02, 6.6343e-03, 3.3068e-02,\n         3.0170e-02, 1.3684e-02],\n        [8.3379e-01, 7.6398e-01, 9.1090e-01, 9.6201e-01, 6.7338e-01, 1.1785e+00,\n         7.3362e-01, 8.8848e-01, 1.1357e+00, 8.2027e-01, 6.9933e-01, 7.0585e-01,\n         6.6902e-01, 8.1132e-01, 1.0093e+00, 7.1613e-01, 9.5998e-01, 9.9003e-01,\n         8.7033e-01, 7.0074e-01, 8.5759e-01, 9.2940e-01, 7.8037e-01, 6.3572e-01,\n         8.8843e-01, 6.4847e-01, 7.9280e-01, 7.9467e-01, 7.3082e-01, 8.4703e-01,\n         9.1469e-01, 7.8461e-01],\n        [3.6605e-04, 1.8229e-06, 2.0475e-03, 4.7173e-03, 4.4749e-05, 4.0856e-02,\n         3.4350e-04, 5.8419e-04, 3.5253e-05, 5.0179e-04, 1.9109e-06, 4.2930e-05,\n         2.3307e-06, 7.5691e-04, 2.6894e-05, 2.7842e-04, 8.5619e-03, 6.3946e-03,\n         1.0467e-03, 1.7476e-06, 4.0787e-04, 1.1375e-02, 1.5742e-04, 1.9764e-06,\n         4.3740e-03, 3.2210e-06, 2.6666e-04, 6.4308e-04, 8.7734e-05, 3.7433e-04,\n         9.3748e-03, 5.1889e-04],\n        [6.0411e-20, 0.0000e+00, 2.9393e-02, 3.4464e+03, 1.1648e-19, 1.9908e-03,\n         2.8654e-19, 1.6228e-22, 1.0734e-42, 3.2472e-13, 0.0000e+00, 1.0993e-25,\n         0.0000e+00, 7.9197e-16, 6.7683e-43, 1.5610e-18, 2.1801e+06, 5.3252e+05,\n         9.4358e-15, 0.0000e+00, 2.9404e-21, 1.9890e-10, 1.0555e-18, 0.0000e+00,\n         3.8014e-13, 0.0000e+00, 1.2837e-19, 1.4349e-15, 1.8493e-19, 4.7813e-20,\n         2.7426e-12, 7.8435e-19],\n        [2.6098e-01, 1.2368e-01, 4.9007e-01, 7.0046e-01, 1.4205e-01, 7.0817e-01,\n         2.4195e-01, 2.9552e-01, 2.7868e-01, 2.7703e-01, 1.0085e-01, 1.7409e-01,\n         9.0759e-02, 4.2809e-01, 2.5736e-01, 2.2880e-01, 7.1906e-01, 6.3564e-01,\n         4.9630e-01, 1.0225e-01, 2.4795e-01, 7.9825e-01, 2.2116e-01, 1.0193e-01,\n         5.3871e-01, 1.0867e-01, 2.5201e-01, 3.3489e-01, 1.8592e-01, 3.0929e-01,\n         6.7096e-01, 3.6450e-01],\n        [8.6777e-01, 8.0322e-01, 9.2022e-01, 9.6998e-01, 6.9284e-01, 1.2004e+00,\n         7.6920e-01, 9.1880e-01, 1.1682e+00, 8.3030e-01, 7.2498e-01, 7.2455e-01,\n         7.0668e-01, 7.9526e-01, 1.0470e+00, 7.4680e-01, 9.6388e-01, 9.8772e-01,\n         8.5914e-01, 7.3644e-01, 8.9028e-01, 9.1960e-01, 7.9143e-01, 6.6784e-01,\n         8.7327e-01, 6.8052e-01, 8.2445e-01, 8.0122e-01, 7.5363e-01, 8.7387e-01,\n         9.1059e-01, 7.7333e-01],\n        [5.7221e-05, 9.6137e-10, 3.4005e+00, 4.5710e+01, 9.7215e-05, 1.4940e-01,\n         8.2537e-05, 1.8138e-05, 5.8216e-08, 2.1767e-02, 6.4495e-10, 4.2185e-05,\n         8.2099e-10, 2.3474e-04, 3.6756e-08, 1.0737e-04, 1.2288e+02, 1.2146e+02,\n         2.8269e-04, 6.1196e-10, 2.6223e-05, 1.5377e-03, 1.7818e-04, 1.8856e-09,\n         6.2675e-04, 1.2442e-09, 8.0998e-05, 2.9331e-04, 1.2841e-04, 4.7653e-05,\n         9.5914e-04, 4.6535e-05],\n        [8.1250e-01, 7.8120e-01, 9.0188e-01, 9.7769e-01, 6.3905e-01, 1.1113e+00,\n         6.9280e-01, 8.5058e-01, 1.1329e+00, 8.3771e-01, 7.1455e-01, 7.0784e-01,\n         7.0050e-01, 7.1353e-01, 1.0250e+00, 6.8427e-01, 9.5482e-01, 9.9763e-01,\n         7.3535e-01, 7.2395e-01, 8.3399e-01, 8.1253e-01, 7.0790e-01, 6.5680e-01,\n         7.8060e-01, 6.7418e-01, 7.6160e-01, 7.3975e-01, 6.8889e-01, 8.2607e-01,\n         7.9312e-01, 6.8589e-01]], device='cuda:0', grad_fn=<ExpBackward0>)"
     ]
    }
   ],
   "source": [
    "vae = baselineVAEAutoencoder(\n",
    "    irreps = None, # not used rn \n",
    "    in_channels = 3,\n",
    "    out_channels = 16,\n",
    "    kernel_size = 5,\n",
    "    stride = 1,\n",
    "    padding = 0,\n",
    "    dilation = 1,\n",
    "    groups = 1,\n",
    "    bias = True,\n",
    "    padding_mode = 'zeros',\n",
    "    latent_dim = 4, # final vae hidden layer \n",
    "    num_layers = 2, # not used rn \n",
    "    hidden_dim = 32,\n",
    "    activation = 'relu', # not used rn \n",
    "    dropout = 0.1, # not used rn \n",
    "    batch_norm = False, # not used rn \n",
    "    beta = 1.0,\n",
    "    device = device,\n",
    "    learning_rate = 0.001\n",
    ")\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=30)\n",
    "trainer.fit(vae, dataset_loader_train, dataset_loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bondnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0 (default, Oct  9 2018, 10:31:47) \n[GCC 7.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c205a9eb4435b0aa27aaf0e9c4340d2b9512e0cc8b49dbd290219ad3711c312f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
