{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from e3nn.non_linearities.rescaled_act import sigmoid, swish, tanh\n",
    "from e3nn.non_linearities.norm_activation import NormActivation\n",
    "from e3nn.batchnorm import BatchNorm\n",
    "from e3nn.image.convolution import Convolution\n",
    "\n",
    "\n",
    "def ConvBlock(Rs_in, Rs_out, size, stride, fpix):\n",
    "    return nn.Sequential(\n",
    "    Convolution(Rs_in, Rs_out, size = size, stride = stride, padding = size//2, bias=None, fuzzy_pixels = fpix),\n",
    "    NormActivation(Rs_out, swish, normalization = 'norm'),\n",
    "    )\n",
    "\n",
    "def ConvTBlock(Rs_in, Rs_out, size, fpix):\n",
    "    return nn.Sequential(\n",
    "    Convolution(Rs_in, Rs_out, size=size, stride=2, padding=size//2, bias=None, output_padding=1, transpose=True, fuzzy_pixels = fpix),\n",
    "    #NormActivation(Rs_out, swish, normalization = 'componenet'),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VNet(nn.Module):\n",
    "    def __init__(self, size, n_reps, inp_channels):\n",
    "        super().__init__()\n",
    "        #super(VNet, self).init()\n",
    "        Rs_in = [(inp_channels,0)]\n",
    "        Rs_out =  [(inp_channels,0)]\n",
    "        m = inp_channels\n",
    "\n",
    "        n_vec, n_ten = n_reps\n",
    "        RsSca = [0]; RsVec = [1] * n_vec; RsTen = [2] * n_ten\n",
    "        Rs = RsSca * m\n",
    "        Rs1 = RsVec + RsTen\n",
    "        fp = True  #option to add noise to conv kernels\n",
    "        \n",
    "        #down\n",
    "        self.dw1 = ConvBlock(Rs_in,          Rs +  Rs1, size=size, stride = 2, fpix=fp)\n",
    "        self.dw2 = ConvBlock(   Rs +  Rs1, 2*Rs +  Rs1, size=size, stride = 2, fpix=fp)\n",
    "        self.dw3 = ConvBlock(2* Rs +  Rs1, 2*Rs +  Rs1, size=size, stride = 2, fpix=fp)\n",
    "        self.dw4 = ConvBlock(2* Rs +  Rs1, 2*Rs +  Rs1, size=size, stride = 2, fpix=fp)\n",
    "        \n",
    "        #up\n",
    "        self.up1 = ConvTBlock( 2*Rs + Rs1, 2*Rs + Rs1, size=size, fpix=fp)\n",
    "        self.cd1 = ConvBlock(  2*Rs + Rs1, 2*Rs + Rs1,  size=size, stride = 1, fpix=fp)\n",
    "        self.up2 = ConvTBlock( 2*Rs + Rs1, 2*Rs + Rs1,  size=size, fpix=fp)\n",
    "        self.cd2 = ConvBlock(  2*Rs + Rs1, 2*Rs + Rs1,  size=size, stride = 1, fpix=fp)\n",
    "        self.up3 = ConvTBlock( 2*Rs + Rs1, 2*Rs + Rs1,  size=size, fpix=fp)\n",
    "        self.cd3 = ConvBlock(  2*Rs + Rs1,   Rs + Rs1,  size=size, stride = 1, fpix=fp)\n",
    "        self.up4 = ConvTBlock(   Rs + Rs1,   Rs + Rs1,  size=size, fpix=fp)\n",
    "        self.cd4 = ConvBlock(    Rs + Rs1,   Rs_out,    size=size, stride = 1, fpix=fp)\n",
    "   \n",
    "    def forward(self, x):\n",
    "        # Down sampling\n",
    "        dw1 = self.dw1(x) \n",
    "        dw2 = self.dw2(dw1) \n",
    "        dw3 = self.dw3(dw2) \n",
    "        dw4 = self.dw4(dw3) \n",
    "        \n",
    "        up1 = self.up1(dw4) \n",
    "        cd1 = self.cd1(up1)\n",
    "        up2 = self.up2(cd1) \n",
    "        cd2 = self.cd2(up2) \n",
    "        up3 = self.up3(cd2) \n",
    "        cd3 = self.cd3(up3) \n",
    "        up4 = self.up4(cd3) \n",
    "        cd4 = self.cd4(up4)\n",
    "        \n",
    "        return cd4, dw4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: torch.Size([2, 16, 16, 16, 11])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "conv3d() received an invalid combination of arguments - got (Tensor, Tensor, transpose=bool, output_padding=int, bias=NoneType, padding=int, stride=int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the keywords were incorrect: transpose, output_padding\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the keywords were incorrect: transpose, output_padding\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_828196/1682069368.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_reps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"latent size: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output size: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet_e3nn/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_828196/3044043164.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mdw4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdw4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdw3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mup1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdw4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mcd1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcd1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mup1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mup2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcd1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet_e3nn/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet_e3nn/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bondnet_e3nn/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/e3nn_old/e3nn/image/convolution.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'xyzij->ijxyz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tixyz->txyzi'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: conv3d() received an invalid combination of arguments - got (Tensor, Tensor, transpose=bool, output_padding=int, bias=NoneType, padding=int, stride=int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the keywords were incorrect: transpose, output_padding\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the keywords were incorrect: transpose, output_padding\n"
     ]
    }
   ],
   "source": [
    "inp_size = 16\n",
    "inp_channels = 11\n",
    "n_reps = [3,1] # n_vectors (L=1), n_tensors (L=2)\n",
    "k_size = 3\n",
    "\n",
    "x = torch.Tensor(2, inp_size, inp_size, inp_size, inp_channels).cuda()\n",
    "#x.to(device)\n",
    "print(\"Input size: {}\".format(x.size()))\n",
    "\n",
    "model = VNet(inp_size, n_reps, inp_channels).cuda()\n",
    "\n",
    "out, latent = model(x)\n",
    "print(\"latent size: {}\".format(latent.size()))\n",
    "print(\"output size: {}\".format(out.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santiagovargas/anaconda3/envs/bondnet_e3nn/lib/python3.7/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484809535/work/aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/home/santiagovargas/dev/e3nn_old/e3nn/rsh.py:231: UserWarning: operator() sees varying value in profiling, ignoring and this should be handled by GUARD logic (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484809535/work/torch/csrc/jit/codegen/cuda/parser.cpp:3513.)\n",
      "  out = mul_m_lm(Rs, sha, shz)\n",
      "/home/santiagovargas/dev/e3nn_old/e3nn/rsh.py:231: UserWarning: operator() profile_node %135 : int[] = prim::profile_ivalue[profile_failed=\"varying profile values\"](%133)\n",
      " does not have profile information (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484809535/work/torch/csrc/jit/codegen/cuda/graph_fuser.cpp:104.)\n",
      "  out = mul_m_lm(Rs, sha, shz)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ec834683e4440aa198e397d9bab0ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViewInteractiveWidget(height=768, layout=Layout(height='auto', width='100%'), width=1024)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pyvista as pv\n",
    "from scipy import ndimage\n",
    "from e3nn import rs\n",
    "from e3nn.image.convolution import Convolution\n",
    "\n",
    "class Simple(nn.Module):\n",
    "    def __init__(self, fuzzy_pixels):\n",
    "        #super(Simple, self).__init__()\n",
    "        super().__init__()\n",
    "\n",
    "        size = 3\n",
    "        self.f = torch.nn.Sequential( Convolution(Rs_in=[0], Rs_out=[0, 1], size=size,  steps=(1., 1., 1.), fuzzy_pixels=fuzzy_pixels),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        out = self.f(x)\n",
    "        return out\n",
    "\n",
    "def rotate(inp, rotation_angle):    \n",
    "    inp = ndimage.interpolation.rotate(inp,\n",
    "                                       angle = rotation_angle,\n",
    "                                       axes=(2,3),\n",
    "                                       reshape=False,\n",
    "                                       order=1,\n",
    "                                       mode= 'nearest',#'constant',\n",
    "                                       cval=0.0)\n",
    "    return inp\n",
    "\n",
    "\n",
    "def VoxPositions(dim, res):\n",
    "    pos = np.empty(shape=(dim*dim*dim,3))\n",
    "    l = 0\n",
    "    for i in range(dim):\n",
    "        for j in range(dim):\n",
    "            for k in range(dim):\n",
    "                pos[l, 0] = i*res + res/2\n",
    "                pos[l, 1] = j*res + res/2\n",
    "                pos[l, 2] = k*res + res/2\n",
    "                l = l + 1 \n",
    "    return pos\n",
    "\n",
    "if __name__=='__main__':\n",
    "\n",
    "    dim = 16;  chans = 1\n",
    "    torch.manual_seed(1000)\n",
    "\n",
    "    # get input\n",
    "    inp = torch.zeros(1, chans, dim, dim, dim)\n",
    "    inp[:, :, dim//2, dim//2, dim//2] = 1.0\n",
    "    inp[:, :, dim//2, 1, dim//2] = 1.0\n",
    "    model = Simple(fuzzy_pixels=True)\n",
    "    \n",
    "    # plotting setup\n",
    "    pl = pv.Plotter(shape=(1, 3))\n",
    "    pl.open_movie('Simple.mp4')\n",
    "    fs = 12 #text font size\n",
    "    cents = VoxPositions(dim=dim-2, res = 1.0)\n",
    "\n",
    "    for i in range(180):\n",
    "        inpR = rotate(inp.numpy(), rotation_angle= i*2.0)\n",
    "        inpR = torch.from_numpy(inpR).float()#.to('cuda')\n",
    "        inpR = torch.einsum('tixyz->txyzi', inpR) #permute\n",
    "                \n",
    "        model.eval()\n",
    "        outR = model(inpR)\n",
    "        outR = torch.einsum('txyzi->tixyz', outR) #unpermute\n",
    "        inpR = torch.einsum('txyzi->tixyz', inpR) #unpermute\n",
    "\n",
    "        OutSca = outR[0, 0, :, :, :].detach().numpy()\n",
    "        OutVec = outR[0, 1:4, :, :, :]\n",
    "        OutVec = OutVec.flatten(1).detach().numpy()\n",
    "\n",
    "        vec = np.array([OutVec[2], OutVec[0], OutVec[1]]).T\n",
    "             \n",
    "        text = \"angle = \" + str(2*i)\n",
    "        pl.subplot(0, 0);  \n",
    "        pl.add_text(\"Input\", position = 'lower_left', font_size = fs)\n",
    "        pl.add_text(text, position = 'upper_left', font_size = fs)\n",
    "        pl.add_volume(inpR[0][0].detach().numpy(), cmap = \"viridis_r\",\n",
    "                      opacity = \"linear\", show_scalar_bar=False)\n",
    "\n",
    "        pl.subplot(0, 1);  \n",
    "        pl.add_text(\"Out Vector\", position = 'lower_left', font_size = fs)\n",
    "        pl.add_arrows(cents, vec, mag=20, show_scalar_bar=False)\n",
    "        \n",
    "        pl.subplot(0, 2);  \n",
    "        pl.add_text(\"Output\", position = 'lower_left', font_size = fs)\n",
    "        OutSca[OutSca < 0.01] = 0.0\n",
    "        pl.add_volume(OutSca, cmap = \"viridis_r\", show_scalar_bar=False)\n",
    "        #pl.add_axes()\n",
    "\n",
    "        if i == 0 :\n",
    "            pl.show(auto_close=False)\n",
    "          \n",
    "        pl.write_frame()\n",
    "        pl.clear()\n",
    "\n",
    "    pl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bondnet_e3nn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b207b546ed9db85640a40bfde077152bd4bf149c5bd635f9999638fb346ceab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
