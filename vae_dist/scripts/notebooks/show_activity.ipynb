{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santiagovargas/anaconda3/envs/bondnet_e3nn/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.18.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=1\n",
    "import pandas as pd \n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly.offline import init_notebook_mode\n",
    "\n",
    "#from vae_dist.core.CNN_regressor import CNNRegressor\n",
    "#from vae_dist.core.ESCNN_regressor import ESCNNRegressor\n",
    "from vae_dist.core.CNN import CNNAutoencoderLightning\n",
    "from vae_dist.core.R3CNN import R3CNN\n",
    "from vae_dist.core.VAE import baselineVAEAutoencoder\n",
    "from vae_dist.core.O3VAE import R3VAE\n",
    "from vae_dist.dataset.dataset import FieldDataset\n",
    "from vae_dist.data.visualize import get_latent_space\n",
    "\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (4, 3, 21, 21, 21)\n",
      "Data type:  float64\n",
      "------------------------- Preprocessing Info -------------------------\n",
      "Helmholtz-Hodge decomposition applied:  False\n",
      "Lower filter applied:  True\n",
      "Log scale applied:  True\n",
      "Standardization applied:  True\n",
      "Min max scaling applied:  False\n",
      "Wrangling outliers applied:  False\n",
      "------------------------- Data Info -------------------------\n",
      "Mean value in dataset:  -0.07833747255515962\n",
      "Standard deviation in dataset:  0.25520290930978556\n",
      "Largest value in dataset:  3.64\n",
      "Smallest value in dataset:  -4.4\n",
      "Nan values in dataset:  False\n",
      "Inf values in dataset:  False\n",
      "Data shape:  (187, 3, 21, 21, 21)\n",
      "Data type:  float64\n",
      "------------------------- Preprocessing Info -------------------------\n",
      "Helmholtz-Hodge decomposition applied:  False\n",
      "Lower filter applied:  True\n",
      "Log scale applied:  True\n",
      "Standardization applied:  True\n",
      "Min max scaling applied:  False\n",
      "Wrangling outliers applied:  False\n",
      "------------------------- Data Info -------------------------\n",
      "Mean value in dataset:  -0.06693137283773543\n",
      "Standard deviation in dataset:  0.2196673043688737\n",
      "Largest value in dataset:  4.96\n",
      "Smallest value in dataset:  -5.21\n",
      "Nan values in dataset:  False\n",
      "Inf values in dataset:  False\n",
      "Data shape:  (748, 3, 21, 21, 21)\n",
      "Data type:  float64\n",
      "------------------------- Preprocessing Info -------------------------\n",
      "Helmholtz-Hodge decomposition applied:  False\n",
      "Lower filter applied:  True\n",
      "Log scale applied:  True\n",
      "Standardization applied:  True\n",
      "Min max scaling applied:  False\n",
      "Wrangling outliers applied:  False\n",
      "------------------------- Data Info -------------------------\n",
      "Mean value in dataset:  -0.0659159127816591\n",
      "Standard deviation in dataset:  0.2191686296286103\n",
      "Largest value in dataset:  4.96\n",
      "Smallest value in dataset:  -5.55\n",
      "Nan values in dataset:  False\n",
      "Inf values in dataset:  False\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "pre_process_options = {\n",
    "    \"transform\": False,\n",
    "    \"augmentation\": False,\n",
    "    \"standardize\": True,\n",
    "    \"lower_filter\": True,\n",
    "    \"log_scale\": True,\n",
    "    \"min_max_scale\": False,\n",
    "    \"wrangle_outliers\": False,\n",
    "    \"scalar\": False,\n",
    "    \"offset\": 1\n",
    "}\n",
    "\n",
    "\n",
    "root = \"../../data/augment_test/\"\n",
    "\n",
    "dataset_test = FieldDataset(\n",
    "    root, \n",
    "    transform=pre_process_options['transform'], \n",
    "    augmentation=pre_process_options['augmentation'],\n",
    "    standardize=pre_process_options['standardize'],\n",
    "    lower_filter=pre_process_options['lower_filter'],\n",
    "    log_scale=pre_process_options['log_scale'], \n",
    "    min_max_scale=pre_process_options['min_max_scale'],\n",
    "    wrangle_outliers=pre_process_options['wrangle_outliers'],\n",
    "    scalar=pre_process_options['scalar'],\n",
    "    device=device, \n",
    "    offset=pre_process_options['offset']\n",
    ")\n",
    " \n",
    "root = \"../../data/cpet/\"\n",
    "\n",
    "dataset = FieldDataset(\n",
    "    root, \n",
    "    transform=pre_process_options['transform'], \n",
    "    augmentation=pre_process_options['augmentation'],\n",
    "    standardize=pre_process_options['standardize'],\n",
    "    lower_filter=pre_process_options['lower_filter'],\n",
    "    log_scale=pre_process_options['log_scale'], \n",
    "    min_max_scale=pre_process_options['min_max_scale'],\n",
    "    wrangle_outliers=pre_process_options['wrangle_outliers'],\n",
    "    scalar=pre_process_options['scalar'],\n",
    "    device=device, \n",
    "    offset=pre_process_options['offset']\n",
    ")\n",
    " \n",
    "\n",
    "root = \"../../data/cpet_augmented/\"\n",
    "dataset_aug_cpet = FieldDataset(\n",
    "    root, \n",
    "    transform=pre_process_options['transform'], \n",
    "    augmentation=pre_process_options['augmentation'],\n",
    "    standardize=pre_process_options['standardize'],\n",
    "    lower_filter=pre_process_options['lower_filter'],\n",
    "    log_scale=pre_process_options['log_scale'], \n",
    "    min_max_scale=pre_process_options['min_max_scale'],\n",
    "    wrangle_outliers=pre_process_options['wrangle_outliers'],\n",
    "    scalar=pre_process_options['scalar'],\n",
    "    device=device, \n",
    "    offset=pre_process_options['offset']\n",
    ")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inner_dim:  1\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1      [-1, 128, 13, 13, 13]         280,064\n",
      "         LeakyReLU-2      [-1, 128, 13, 13, 13]               0\n",
      "       BatchNorm3d-3      [-1, 128, 13, 13, 13]             256\n",
      "         ConvBatch-4      [-1, 128, 13, 13, 13]               0\n",
      "            Conv3d-5          [-1, 64, 5, 5, 5]       5,972,032\n",
      "         LeakyReLU-6          [-1, 64, 5, 5, 5]               0\n",
      "       BatchNorm3d-7          [-1, 64, 5, 5, 5]             128\n",
      "         ConvBatch-8          [-1, 64, 5, 5, 5]               0\n",
      "            Conv3d-9          [-1, 64, 1, 1, 1]         110,656\n",
      "        LeakyReLU-10          [-1, 64, 1, 1, 1]               0\n",
      "      BatchNorm3d-11          [-1, 64, 1, 1, 1]             128\n",
      "        ConvBatch-12          [-1, 64, 1, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 6,363,264\n",
      "Trainable params: 6,363,264\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.11\n",
      "Forward/backward pass size (MB): 8.83\n",
      "Params size (MB): 24.27\n",
      "Estimated Total Size (MB): 33.21\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1      [-1, 128, 13, 13, 13]         280,064\n",
      "         LeakyReLU-2      [-1, 128, 13, 13, 13]               0\n",
      "       BatchNorm3d-3      [-1, 128, 13, 13, 13]             256\n",
      "         ConvBatch-4      [-1, 128, 13, 13, 13]               0\n",
      "            Conv3d-5          [-1, 64, 5, 5, 5]       5,972,032\n",
      "         LeakyReLU-6          [-1, 64, 5, 5, 5]               0\n",
      "       BatchNorm3d-7          [-1, 64, 5, 5, 5]             128\n",
      "         ConvBatch-8          [-1, 64, 5, 5, 5]               0\n",
      "            Conv3d-9          [-1, 64, 1, 1, 1]         110,656\n",
      "        LeakyReLU-10          [-1, 64, 1, 1, 1]               0\n",
      "      BatchNorm3d-11          [-1, 64, 1, 1, 1]             128\n",
      "        ConvBatch-12          [-1, 64, 1, 1, 1]               0\n",
      "          Flatten-13                   [-1, 64]               0\n",
      "           Linear-14                  [-1, 500]          32,500\n",
      "        LeakyReLU-15                  [-1, 500]               0\n",
      "           Linear-16                    [-1, 2]           1,002\n",
      "        LeakyReLU-17                    [-1, 2]               0\n",
      "================================================================\n",
      "Total params: 6,396,766\n",
      "Trainable params: 6,396,766\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.11\n",
      "Forward/backward pass size (MB): 8.84\n",
      "Params size (MB): 24.40\n",
      "Estimated Total Size (MB): 33.34\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 500]           1,500\n",
      "            Linear-2                   [-1, 64]          32,064\n",
      "         LeakyReLU-3                   [-1, 64]               0\n",
      "         Unflatten-4          [-1, 64, 1, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 33,564\n",
      "Trainable params: 33,564\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.13\n",
      "Estimated Total Size (MB): 0.13\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ConvTranspose3d-1          [-1, 64, 5, 5, 5]         512,064\n",
      "         LeakyReLU-2          [-1, 64, 5, 5, 5]               0\n",
      "       BatchNorm3d-3          [-1, 64, 5, 5, 5]             128\n",
      "       UpConvBatch-4          [-1, 64, 5, 5, 5]               0\n",
      "   ConvTranspose3d-5      [-1, 128, 13, 13, 13]       1,024,128\n",
      "         LeakyReLU-6      [-1, 128, 13, 13, 13]               0\n",
      "       BatchNorm3d-7      [-1, 128, 13, 13, 13]             256\n",
      "       UpConvBatch-8      [-1, 128, 13, 13, 13]               0\n",
      "   ConvTranspose3d-9        [-1, 3, 21, 21, 21]         279,939\n",
      "      BatchNorm3d-10        [-1, 3, 21, 21, 21]               6\n",
      "         Identity-11        [-1, 3, 21, 21, 21]               0\n",
      "      UpConvBatch-12        [-1, 3, 21, 21, 21]               0\n",
      "================================================================\n",
      "Total params: 1,816,521\n",
      "Trainable params: 1,816,521\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 9.67\n",
      "Params size (MB): 6.93\n",
      "Estimated Total Size (MB): 16.60\n",
      "----------------------------------------------------------------\n",
      "inner_dim:  1\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1      [-1, 128, 13, 13, 13]         279,936\n",
      "         LeakyReLU-2      [-1, 128, 13, 13, 13]               0\n",
      "       BatchNorm3d-3      [-1, 128, 13, 13, 13]             256\n",
      "         ConvBatch-4      [-1, 128, 13, 13, 13]               0\n",
      "            Conv3d-5          [-1, 64, 5, 5, 5]       5,971,968\n",
      "         LeakyReLU-6          [-1, 64, 5, 5, 5]               0\n",
      "       BatchNorm3d-7          [-1, 64, 5, 5, 5]             128\n",
      "         ConvBatch-8          [-1, 64, 5, 5, 5]               0\n",
      "            Conv3d-9          [-1, 64, 1, 1, 1]         110,592\n",
      "        LeakyReLU-10          [-1, 64, 1, 1, 1]               0\n",
      "      BatchNorm3d-11          [-1, 64, 1, 1, 1]             128\n",
      "        ConvBatch-12          [-1, 64, 1, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 6,363,008\n",
      "Trainable params: 6,363,008\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.11\n",
      "Forward/backward pass size (MB): 8.83\n",
      "Params size (MB): 24.27\n",
      "Estimated Total Size (MB): 33.21\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1      [-1, 128, 13, 13, 13]         279,936\n",
      "         LeakyReLU-2      [-1, 128, 13, 13, 13]               0\n",
      "       BatchNorm3d-3      [-1, 128, 13, 13, 13]             256\n",
      "         ConvBatch-4      [-1, 128, 13, 13, 13]               0\n",
      "            Conv3d-5          [-1, 64, 5, 5, 5]       5,971,968\n",
      "         LeakyReLU-6          [-1, 64, 5, 5, 5]               0\n",
      "       BatchNorm3d-7          [-1, 64, 5, 5, 5]             128\n",
      "         ConvBatch-8          [-1, 64, 5, 5, 5]               0\n",
      "            Conv3d-9          [-1, 64, 1, 1, 1]         110,592\n",
      "        LeakyReLU-10          [-1, 64, 1, 1, 1]               0\n",
      "      BatchNorm3d-11          [-1, 64, 1, 1, 1]             128\n",
      "        ConvBatch-12          [-1, 64, 1, 1, 1]               0\n",
      "          Flatten-13                   [-1, 64]               0\n",
      "           Linear-14                  [-1, 100]           6,500\n",
      "        LeakyReLU-15                  [-1, 100]               0\n",
      "      BatchNorm1d-16                  [-1, 100]             200\n",
      "           Linear-17                   [-1, 50]           5,050\n",
      "        LeakyReLU-18                   [-1, 50]               0\n",
      "      BatchNorm1d-19                   [-1, 50]             100\n",
      "================================================================\n",
      "Total params: 6,374,858\n",
      "Trainable params: 6,374,858\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.11\n",
      "Forward/backward pass size (MB): 8.83\n",
      "Params size (MB): 24.32\n",
      "Estimated Total Size (MB): 33.26\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                   [-1, 50]             100\n",
      "            Linear-2                  [-1, 100]           5,100\n",
      "         LeakyReLU-3                  [-1, 100]               0\n",
      "       BatchNorm1d-4                  [-1, 100]             200\n",
      "            Linear-5                   [-1, 64]           6,464\n",
      "         LeakyReLU-6                   [-1, 64]               0\n",
      "       BatchNorm1d-7                   [-1, 64]             128\n",
      "         Unflatten-8          [-1, 64, 1, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 11,992\n",
      "Trainable params: 11,992\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.05\n",
      "Estimated Total Size (MB): 0.05\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ConvTranspose3d-1          [-1, 64, 5, 5, 5]         512,000\n",
      "         LeakyReLU-2          [-1, 64, 5, 5, 5]               0\n",
      "       BatchNorm3d-3          [-1, 64, 5, 5, 5]             128\n",
      "       UpConvBatch-4          [-1, 64, 5, 5, 5]               0\n",
      "   ConvTranspose3d-5      [-1, 128, 13, 13, 13]       1,024,000\n",
      "         LeakyReLU-6      [-1, 128, 13, 13, 13]               0\n",
      "       BatchNorm3d-7      [-1, 128, 13, 13, 13]             256\n",
      "       UpConvBatch-8      [-1, 128, 13, 13, 13]               0\n",
      "   ConvTranspose3d-9        [-1, 3, 21, 21, 21]         279,936\n",
      "      BatchNorm3d-10        [-1, 3, 21, 21, 21]               6\n",
      "         Identity-11        [-1, 3, 21, 21, 21]               0\n",
      "      UpConvBatch-12        [-1, 3, 21, 21, 21]               0\n",
      "================================================================\n",
      "Total params: 1,816,326\n",
      "Trainable params: 1,816,326\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 9.67\n",
      "Params size (MB): 6.93\n",
      "Estimated Total Size (MB): 16.60\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "loc_escnn = \"./logs/log_version_escnn_1/test_logs/version_1/checkpoints/epoch=999-step=5000.ckpt\"\n",
    "loc_esvae = \"./logs/log_version_esvae_1/test_logs/version_1/checkpoints/epoch=999-step=5000.ckpt\"\n",
    "loc_cnn =  \"./logs/log_version_auto_1/test_logs/version_2/checkpoints/epoch=719-step=3600.ckpt\"\n",
    "loc_vae = \"./logs/log_version_vae_1/test_logs/version_0/checkpoints/epoch=274-step=1375.ckpt\"\n",
    "#escnn = R3CNN.load_from_checkpoint(loc_escnn)\n",
    "#esvae = R3VAE.load_from_checkpoint(loc_esvae)\n",
    "cnn = CNNAutoencoderLightning.load_from_checkpoint(loc_cnn)\n",
    "vae = baselineVAEAutoencoder.load_from_checkpoint(loc_vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "baselineVAEAutoencoder(\n",
       "  (fc_mu): Linear(in_features=50, out_features=1, bias=True)\n",
       "  (fc_var): Linear(in_features=50, out_features=1, bias=True)\n",
       "  (encoder_conv): Sequential(\n",
       "    (0): ConvBatch(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv3d(3, 128, kernel_size=(9, 9, 9), stride=(1, 1, 1), bias=False)\n",
       "        (1): LeakyReLU(negative_slope=0.2)\n",
       "        (2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ConvBatch(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv3d(128, 64, kernel_size=(9, 9, 9), stride=(1, 1, 1), bias=False)\n",
       "        (1): LeakyReLU(negative_slope=0.2)\n",
       "        (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): ConvBatch(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(3, 3, 3), bias=False)\n",
       "        (1): LeakyReLU(negative_slope=0.2)\n",
       "        (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder_conv): Sequential(\n",
       "    (0): UpConvBatch(\n",
       "      (up): Sequential(\n",
       "        (0): ConvTranspose3d(64, 64, kernel_size=(5, 5, 5), stride=(3, 3, 3), bias=False)\n",
       "        (1): LeakyReLU(negative_slope=0.2)\n",
       "        (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): UpConvBatch(\n",
       "      (up): Sequential(\n",
       "        (0): ConvTranspose3d(64, 128, kernel_size=(5, 5, 5), stride=(2, 2, 2), bias=False)\n",
       "        (1): LeakyReLU(negative_slope=0.2)\n",
       "        (2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): UpConvBatch(\n",
       "      (up): Sequential(\n",
       "        (0): ConvTranspose3d(128, 3, kernel_size=(9, 9, 9), stride=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder_dense): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
       "    (1): Linear(in_features=50, out_features=100, bias=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): Linear(in_features=100, out_features=64, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "    (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Unflatten(dim=1, unflattened_size=(64, 1, 1, 1))\n",
       "  )\n",
       "  (encoder): Sequential(\n",
       "    (0): ConvBatch(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv3d(3, 128, kernel_size=(9, 9, 9), stride=(1, 1, 1), bias=False)\n",
       "        (1): LeakyReLU(negative_slope=0.2)\n",
       "        (2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ConvBatch(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv3d(128, 64, kernel_size=(9, 9, 9), stride=(1, 1, 1), bias=False)\n",
       "        (1): LeakyReLU(negative_slope=0.2)\n",
       "        (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): ConvBatch(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(3, 3, 3), bias=False)\n",
       "        (1): LeakyReLU(negative_slope=0.2)\n",
       "        (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): Flatten(start_dim=1, end_dim=-1)\n",
       "    (4): Linear(in_features=64, out_features=100, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (8): LeakyReLU(negative_slope=0.01)\n",
       "    (9): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
       "    (1): Linear(in_features=50, out_features=100, bias=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): Linear(in_features=100, out_features=64, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "    (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Unflatten(dim=1, unflattened_size=(64, 1, 1, 1))\n",
       "    (8): UpConvBatch(\n",
       "      (up): Sequential(\n",
       "        (0): ConvTranspose3d(64, 64, kernel_size=(5, 5, 5), stride=(3, 3, 3), bias=False)\n",
       "        (1): LeakyReLU(negative_slope=0.2)\n",
       "        (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): UpConvBatch(\n",
       "      (up): Sequential(\n",
       "        (0): ConvTranspose3d(64, 128, kernel_size=(5, 5, 5), stride=(2, 2, 2), bias=False)\n",
       "        (1): LeakyReLU(negative_slope=0.2)\n",
       "        (2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): UpConvBatch(\n",
       "      (up): Sequential(\n",
       "        (0): ConvTranspose3d(128, 3, kernel_size=(9, 9, 9), stride=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (model): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): ConvBatch(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv3d(3, 128, kernel_size=(9, 9, 9), stride=(1, 1, 1), bias=False)\n",
       "          (1): LeakyReLU(negative_slope=0.2)\n",
       "          (2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ConvBatch(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv3d(128, 64, kernel_size=(9, 9, 9), stride=(1, 1, 1), bias=False)\n",
       "          (1): LeakyReLU(negative_slope=0.2)\n",
       "          (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): ConvBatch(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(3, 3, 3), bias=False)\n",
       "          (1): LeakyReLU(negative_slope=0.2)\n",
       "          (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3): Flatten(start_dim=1, end_dim=-1)\n",
       "      (4): Linear(in_features=64, out_features=100, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (7): Linear(in_features=100, out_features=50, bias=True)\n",
       "      (8): LeakyReLU(negative_slope=0.01)\n",
       "      (9): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=1, out_features=50, bias=True)\n",
       "      (1): Linear(in_features=50, out_features=100, bias=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "      (3): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (4): Linear(in_features=100, out_features=64, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (7): Unflatten(dim=1, unflattened_size=(64, 1, 1, 1))\n",
       "      (8): UpConvBatch(\n",
       "        (up): Sequential(\n",
       "          (0): ConvTranspose3d(64, 64, kernel_size=(5, 5, 5), stride=(3, 3, 3), bias=False)\n",
       "          (1): LeakyReLU(negative_slope=0.2)\n",
       "          (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (9): UpConvBatch(\n",
       "        (up): Sequential(\n",
       "          (0): ConvTranspose3d(64, 128, kernel_size=(5, 5, 5), stride=(2, 2, 2), bias=False)\n",
       "          (1): LeakyReLU(negative_slope=0.2)\n",
       "          (2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (10): UpConvBatch(\n",
       "        (up): Sequential(\n",
       "          (0): ConvTranspose3d(128, 3, kernel_size=(9, 9, 9), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (train_rmse): MeanSquaredError()\n",
       "  (val_rmse): MeanSquaredError()\n",
       "  (test_rmse): MeanSquaredError()\n",
       "  (test_mae): MeanAbsoluteError()\n",
       "  (train_mae): MeanAbsoluteError()\n",
       "  (val_mae): MeanAbsoluteError()\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#options = json.load(open('./options/options_escnn_default.json'))\n",
    "#model_escnn = construct_model(\"escnn\", options)\n",
    "#options = json.load(open('./options/options_esvae_default.json'))\n",
    "#model_esvae = construct_model(\"esvae\", options)\n",
    "#options = json.load(open('./options/options_cnn_default.json'))\n",
    "#model_cnn = construct_model(\"cnn\", options)\n",
    "#options = json.load(open('./options/options_vae_default.json'))\n",
    "#model_vae = construct_model(\"vae\", options)\n",
    "\n",
    "#model_esvae.load_model(\"./logs/log_version_esvae_1/model_1.ckpt\")\n",
    "#model_esvae.load_model(\"./logs/log_version_esvae_1/model_single_datapoint.ckpt\")\n",
    "#model_escnn.load_model(\"./logs/log_version_escnn_1/model_single_datapoint.ckpt\")\n",
    "\n",
    "#model_escnn.load_model(\"./logs/log_version_escnn_1/model_1.ckpt\")\n",
    "# move model to gpu \n",
    "cnn.to(device)\n",
    "#model_escnn.to(device)\n",
    "#model_esvae.to(device)\n",
    "vae.to(device)\n",
    "cnn.eval()\n",
    "#model_escnn.eval()\n",
    "#model_esvae.eval()\n",
    "vae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of fields:  187\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 187 into shape (2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1466109/207549885.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"H\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Y\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mlatent_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_latent_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mscatter_plot_color_by_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlatent_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/vae_dist/vae_dist/data/visualize.py\u001b[0m in \u001b[0;36mget_latent_space\u001b[0;34m(model, dataset, comp, latent_dim, field_dims)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 187 into shape (2)"
     ]
    }
   ],
   "source": [
    "def scatter_plot_color_by_class(latent_space, labels):\n",
    "    plt.scatter(\n",
    "        latent_space[:, 0], \n",
    "        latent_space[:, 1], \n",
    "        c=labels, \n",
    "        cmap=\"tab10\"\n",
    "    )\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def pull_labels(\n",
    "    names, dir_data=\"../../../data/protein_data.csv\"\n",
    "):\n",
    "    # iterate through names \n",
    "    # pull labels from csv file\n",
    "    # return list of labels\n",
    "    labels = []\n",
    "    df = pd.read_csv(dir_data)\n",
    "    for name in names:\n",
    "        for row in df.iterrows():\n",
    "            if name == row[1][\"name\"]:\n",
    "                labels.append(row[1][\"label\"])\n",
    "    return labels\n",
    "\n",
    "\n",
    "list_name = dataset.names\n",
    "raw_names = [name.split(\"_\")[2].split(\".\")[0] for name in list_name]\n",
    "labels = pull_labels(raw_names, dir_data=\"../../data/protein_data.csv\")\n",
    "# convert labels to colors where H = red Y = blue and C = green\n",
    "\n",
    "labels = [0 if label == \"H\" else 1 if label == \"Y\" else 2 for label in labels]\n",
    "\n",
    "latent_space = get_latent_space(vae, dataset, latent_dim=2, comp=[0,1])\n",
    "print(latent_space)\n",
    "scatter_plot_color_by_class(latent_space = latent_space, labels= labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bondnet_e3nn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b207b546ed9db85640a40bfde077152bd4bf149c5bd635f9999638fb346ceab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
